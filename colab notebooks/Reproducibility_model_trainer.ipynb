{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Reproducibility challenge: Ganformer\n",
        "##Stefano Carlo Lambertenghi, Felix Boelter, Giorgia Aurora Adorni\n",
        "###Training system\n",
        "\n",
        "USE: Allows for training of Stylegan2, Ganformer with simplex attention, Ganformer with duplex attention, \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF_Ce0gGyfaP",
        "outputId": "5b4e57d0-0f9b-465c-8fa1-b555d0234e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gansformer-reproducibility-challenge'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 127 (delta 13), reused 127 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (127/127), 74.29 MiB | 41.55 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/GiorgiaAuroraAdorni/gansformer-reproducibility-challenge.git\n",
        "\n",
        "!git clone https://github.com/karen-jin/gansformer-reproducibility-challenge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U numpy==1.18.5"
      ],
      "metadata": {
        "id": "YoYZ3FAugvJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcaee9a3-3d5f-43ff-ec31-4019fb69f863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (1.18.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzDuIoMcqfBT",
        "outputId": "e3a6a971-66ad-48b2-aece-62e340511fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Tensorflow version: 1.15.2\n",
            "Numpy version: 1.21.5\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-9449e6ac-f29e-5852-8f27-6ebe74f4c629)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import gdown\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "print('Numpy version: {}'.format(np.__version__) )\n",
        "\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vMBDq2Chyli",
        "outputId": "8c6b1f9d-e5f6-4167-f363-862b750e6ab3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gansformer-repo-challenge  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load mnist dataset \n",
        "%cd /content/gansformer-reproducibility-challenge/src/\n",
        "import dataset_tool \n",
        "dataset_tool.create_mnist_testset('custom', './')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d21LthQhvi8Y",
        "outputId": "0206e6c6-c8ac-456b-f8e2-130a4c530bca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gansformer-reproducibility-challenge/src\n",
            "Loading MNIST from \"./\"\n",
            "Creating dataset \"custom\"\n",
            "Added 10000 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEMscuV6qk9u",
        "outputId": "66c78214-16c5-4520-dcf8-463ff84308c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gansformer-reproducibility-challenge/src/training\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gansformer-reproducibility-challenge/src/training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVoMnq1jNE-",
        "outputId": "38b7bb76-68ec-4e04-998d-e3d141d3635e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting training_loop.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile training_loop.py\n",
        "\n",
        "# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n",
        "#\n",
        "# This work is made available under the Nvidia Source Code License-NC.\n",
        "# To view a copy of this license, visit\n",
        "# https://nvlabs.github.io/stylegan2/license.html\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "from training import misc\n",
        "from metrics import metric_base\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "import gc\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Just-in-time processing of training images before feeding them to the networks.\n",
        "\n",
        "def process_reals(x, labels, lod, mirror_augment, drange_data, drange_net):\n",
        "    with tf.name_scope('DynamicRange'):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
        "    if mirror_augment:\n",
        "        with tf.name_scope('MirrorAugment'):\n",
        "            x = tf.where(tf.random_uniform([tf.shape(x)[0]]) < 0.5, x, tf.reverse(x, [3]))\n",
        "    with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
        "        s = tf.shape(x)\n",
        "        y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
        "        y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
        "        y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
        "        y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
        "        x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
        "    with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
        "        s = tf.shape(x)\n",
        "        factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
        "        x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "        x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "        x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Evaluate time-varying training parameters.\n",
        "\n",
        "def training_schedule(\n",
        "    cur_nimg,\n",
        "    training_set,\n",
        "    lod_initial_resolution  = None,     # Image resolution used at the beginning.\n",
        "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
        "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
        "    minibatch_size_base     = 16,       # Global minibatch size.\n",
        "    minibatch_size_dict     = {},       # Resolution-specific overrides.\n",
        "    minibatch_gpu_base      = 4,        # Number of samples processed at a time by one GPU.\n",
        "    minibatch_gpu_dict      = {},       # Resolution-specific overrides.\n",
        "    G_lrate_base            = 0.002,    # Learning rate for the generator.\n",
        "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    D_lrate_base            = 0.002,    # Learning rate for the discriminator.\n",
        "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
        "    tick_kimg_base          = 160,        # Default interval of progress snapshots.\n",
        "    tick_size               = 16): # Resolution-specific overrides.\n",
        "\n",
        "    # Initialize result dict.\n",
        "    s = dnnlib.EasyDict()\n",
        "    s.kimg = cur_nimg / 1000.0\n",
        "\n",
        "    # Training phase.\n",
        "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
        "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
        "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
        "    # Level-of-detail and resolution.\n",
        "    if lod_initial_resolution is None:\n",
        "        s.lod = 0.0\n",
        "    else:\n",
        "        s.lod = training_set.resolution_log2\n",
        "        s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
        "        s.lod -= phase_idx\n",
        "        if lod_transition_kimg > 0:\n",
        "            s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
        "        s.lod = max(s.lod, 0.0)\n",
        "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
        "\n",
        "    # Minibatch size.\n",
        "    s.minibatch_size = minibatch_size_dict.get(s.resolution, minibatch_size_base)\n",
        "    s.minibatch_gpu = minibatch_gpu_dict.get(s.resolution, minibatch_gpu_base)\n",
        "\n",
        "    # Learning rate.\n",
        "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
        "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
        "    if lrate_rampup_kimg > 0:\n",
        "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
        "        s.G_lrate *= rampup\n",
        "        s.D_lrate *= rampup\n",
        "\n",
        "    # Other parameters.\n",
        "    s.tick_kimg = tick_size\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    G_loss_args             = {},       # Options for generator loss.\n",
        "    D_loss_args             = {},       # Options for discriminator loss.\n",
        "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
        "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
        "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
        "    metric_arg_list         = [],       # Options for MetricGroup.\n",
        "    metrics_10k_arg_list    = [],       # Options for MetricGroup_10k.\n",
        "    tf_config               = {},       # Options for tflib.init_tf().\n",
        "    data_dir                = None,     # Directory to load datasets from.\n",
        "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    mirror_augment          = False,    # Enable mirror augment?\n",
        "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
        "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 0,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    resume_with_new_nets    = False,\n",
        "    tick_size               = 16,\n",
        "    snapshot_saving_size    = 2,        # Number of snapshots to save\n",
        "    ganformer=True):   # Construct new networks according to G_args and D_args before resuming training?\n",
        "\n",
        "    # Initialize dnnlib and TensorFlow.\n",
        "    tflib.init_tf(tf_config)\n",
        "    num_gpus = dnnlib.submit_config.num_gpus\n",
        "\n",
        "    # Load training set.\n",
        "    training_set = dataset.load_dataset(data_dir=dnnlib.convert_path(data_dir), verbose=True, **dataset_args)\n",
        "    grid_size, grid_reals, grid_labels = misc.setup_snapshot_image_grid(training_set, **grid_args)\n",
        "    misc.save_image_grid(grid_reals, dnnlib.make_run_dir_path('reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
        "\n",
        "    # Construct or load networks.\n",
        "    with tf.device('/gpu:0'):\n",
        "        if resume_pkl is None or resume_with_new_nets:\n",
        "            print('Constructing networks...')\n",
        "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "            Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print('Loading networks from \"%s\"...' % resume_pkl)\n",
        "            rG, rD, rGs = misc.load_pkl(resume_pkl)\n",
        "            if resume_with_new_nets: G.copy_vars_from(rG); D.copy_vars_from(rD); Gs.copy_vars_from(rGs)\n",
        "            else: G = rG; D = rD; Gs = rGs\n",
        "\n",
        "    # Print layers and generate initial image snapshot.\n",
        "    G.print_layers(); D.print_layers()\n",
        "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, tick_size=tick_size, **sched_args)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "    grid=grid_fakes\n",
        "    if ganformer:\n",
        "      grid=grid_fakes[0]\n",
        "    misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes_init.png'), drange=drange_net, grid_size=grid_size)\n",
        "\n",
        "    # Setup training inputs.\n",
        "    print('Building TensorFlow graph...')\n",
        "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
        "        lod_in               = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
        "        lrate_in             = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
        "        minibatch_size_in    = tf.placeholder(tf.int32, name='minibatch_size_in', shape=[])\n",
        "        minibatch_gpu_in     = tf.placeholder(tf.int32, name='minibatch_gpu_in', shape=[])\n",
        "        minibatch_multiplier = minibatch_size_in // (minibatch_gpu_in * num_gpus)\n",
        "        Gs_beta              = 0.5 ** tf.div(tf.cast(minibatch_size_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
        "\n",
        "    # Setup optimizers.\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_multiplier\n",
        "        args['learning_rate'] = lrate_in\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    # Build training graph for each GPU.\n",
        "    data_fetch_ops = []\n",
        "    for gpu in range(num_gpus):\n",
        "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
        "\n",
        "            # Create GPU-specific shadow copies of G and D.\n",
        "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
        "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                sched = training_schedule(cur_nimg=int(resume_kimg*1000), training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "                reals_var = tf.Variable(name='reals', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu] + training_set.shape))\n",
        "                labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu, training_set.label_size]))\n",
        "                reals_write, labels_write = training_set.get_minibatch_tf()\n",
        "                reals_write, labels_write = process_reals(reals_write, labels_write, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
        "                reals_write = tf.concat([reals_write, reals_var[minibatch_gpu_in:]], axis=0)\n",
        "                labels_write = tf.concat([labels_write, labels_var[minibatch_gpu_in:]], axis=0)\n",
        "                data_fetch_ops += [tf.assign(reals_var, reals_write)]\n",
        "                data_fetch_ops += [tf.assign(labels_var, labels_write)]\n",
        "                reals_read = reals_var[:minibatch_gpu_in]\n",
        "                labels_read = labels_var[:minibatch_gpu_in]\n",
        "\n",
        "            # Evaluate loss functions.\n",
        "            lod_assign_ops = []\n",
        "            if 'lod' in G_gpu.vars: lod_assign_ops += [tf.assign(G_gpu.vars['lod'], lod_in)]\n",
        "            if 'lod' in D_gpu.vars: lod_assign_ops += [tf.assign(D_gpu.vars['lod'], lod_in)]\n",
        "            with tf.control_dependencies(lod_assign_ops):\n",
        "                with tf.name_scope('G_loss'):\n",
        "                    G_loss, G_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, **G_loss_args)\n",
        "                with tf.name_scope('D_loss'):\n",
        "                    D_loss, D_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, reals=reals_read, labels=labels_read, **D_loss_args)\n",
        "\n",
        "            # Register gradients.\n",
        "            if not lazy_regularization:\n",
        "                if G_reg is not None: G_loss += G_reg\n",
        "                if D_reg is not None: D_loss += D_reg\n",
        "            else:\n",
        "                if G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
        "\n",
        "    # Setup training ops.\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
        "\n",
        "    # Finalize graph.\n",
        "    with tf.device('/gpu:0'):\n",
        "        try:\n",
        "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "        except tf.errors.NotFoundError:\n",
        "            peak_gpu_mem_op = tf.constant(0)\n",
        "    tflib.init_uninitialized_vars()\n",
        "\n",
        "    print('Initializing logs...')\n",
        "    summary_log = tf.summary.FileWriter(dnnlib.make_run_dir_path())\n",
        "    if save_tf_graph:\n",
        "        summary_log.add_graph(tf.get_default_graph())\n",
        "    if save_weight_histograms:\n",
        "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
        "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
        "    metrics_10k = metric_base.MetricGroup(metrics_10k_arg_list)\n",
        "\n",
        "    print('Training for %d kimg...\\n' % total_kimg)\n",
        "    dnnlib.RunContext.get().update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
        "    maintenance_time = dnnlib.RunContext.get().get_last_update_interval()\n",
        "    cur_nimg = int(resume_kimg * 1000)\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    prev_lod = -1.0\n",
        "    running_mb_counter = 0\n",
        "    while cur_nimg < total_kimg * 1000:\n",
        "        if dnnlib.RunContext.get().should_stop(): break\n",
        "\n",
        "        # Choose training parameters and configure training ops.\n",
        "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "        assert sched.minibatch_size % (sched.minibatch_gpu * num_gpus) == 0\n",
        "        training_set.configure(sched.minibatch_gpu, sched.lod)\n",
        "        if reset_opt_for_new_lod:\n",
        "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
        "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
        "        prev_lod = sched.lod\n",
        "\n",
        "        # Run training ops.\n",
        "        feed_dict = {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_size_in: sched.minibatch_size, minibatch_gpu_in: sched.minibatch_gpu}\n",
        "        for _repeat in range(minibatch_repeats):\n",
        "            rounds = range(0, sched.minibatch_size, sched.minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += sched.minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op], feed_dict)\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run([D_train_op, Gs_update_op], feed_dict)\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op, feed_dict)\n",
        "                if run_G_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run(Gs_update_op, feed_dict)\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op, feed_dict)\n",
        "                    tflib.run(D_train_op, feed_dict)\n",
        "                if run_D_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000)\n",
        "        if cur_tick < 0 or cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_time = dnnlib.RunContext.get().get_time_since_last_update()\n",
        "            total_time = dnnlib.RunContext.get().get_time_since_start() + resume_time\n",
        "\n",
        "            # Report progress.\n",
        "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %.1f' % (\n",
        "                autosummary('Progress/tick', cur_tick),\n",
        "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
        "                autosummary('Progress/lod', sched.lod),\n",
        "                autosummary('Progress/minibatch', sched.minibatch_size),\n",
        "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
        "                autosummary('Timing/sec_per_tick', tick_time),\n",
        "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
        "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
        "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (cur_tick % image_snapshot_ticks == 0 or done):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "                grid=grid_fakes\n",
        "                if ganformer:\n",
        "                  grid=grid_fakes[0]\n",
        "                misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes%06d.png') % (cur_nimg // 1000), drange=drange_net, grid_size=grid_size)\n",
        "            if network_snapshot_ticks is not None and (cur_tick % network_snapshot_ticks == 0 or done):\n",
        "                pkl = dnnlib.make_run_dir_path('network-snapshot-%06d.pkl') % (cur_nimg // 1000)\n",
        "                misc.save_pkl((G, D, Gs), pkl)\n",
        "                metrics_10k.run(dnnlib.make_run_dir_path(('network-snapshot-%06d.pkl')% (cur_nimg // 1000)), run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config, ganformer=ganformer)\n",
        "                gc.collect(generation=2)\n",
        "            if snapshot_saving_size > 0:\n",
        "              files_to_remove = sorted(glob.glob(dnnlib.make_run_dir_path(\"network*.pkl\")))[:-snapshot_saving_size]\n",
        "              for f in files_to_remove:\n",
        "                os.remove(f)\n",
        "            # Update summaries and RunContext.\n",
        "            metrics.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            dnnlib.RunContext.get().update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
        "            maintenance_time = dnnlib.RunContext.get().get_last_update_interval() - tick_time\n",
        "\n",
        "    # Save final snapshot.\n",
        "    misc.save_pkl((G, D, Gs), dnnlib.make_run_dir_path('network-final.pkl'))\n",
        "    metrics.run(dnnlib.make_run_dir_path('network-final.pkl'), run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config, ganformer=ganformer)\n",
        "    # All done.\n",
        "    summary_log.close()\n",
        "    training_set.close()\n",
        "\n",
        "  #----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhfj6YBxwAdb",
        "outputId": "f47bea8e-af4d-4362-e1da-f50189696318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gansformer-reproducibility-challenge/src\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pufC7hNgpA_Y",
        "outputId": "e6505ca8-257e-4b3f-9a16-5f19dc3e3b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_training.py\n",
        "# setup\n",
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "import numpy as np\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "\n",
        "\n",
        "ganformer=True\n",
        "duplex=False\n",
        "attention_discriminator=False\n",
        "#tfrecords_dataset = 'FFHQ'\n",
        "tfrecords_dataset = 'Cartoon'\n",
        "img_resolution = 64 if tfrecords_dataset == 'Cartoon' else 128 #Resolution of the Image default 64 for Cartoon 128 for FFHQ\n",
        "\n",
        "\n",
        "\n",
        "base_2_log = int(np.log2(img_resolution))\n",
        "dataset = 'custom'\n",
        "# data_dir = '/content/datasets/' if tfrecords_dataset == 'Cartoon' else '/content/TFRecords_FFHQ/'\n",
        "\n",
        "# train with mnist dataset\n",
        "data_dir = '/content/gansformer-reproducibility-challenge/src'\n",
        "img_resolution = 32\n",
        "\n",
        "num_gpus = 1\n",
        "total_kimg = 300\n",
        "mirror_augment = True\n",
        "metrics = ['fid50k', 'is50k','pr50k3'] #' \n",
        "metrics_10k = ['fid10k']\n",
        "gamma = None\n",
        "tick_size=16\n",
        "result_dir = '/content/drive/MyDrive/model'\n",
        "if ganformer:\n",
        "    result_dir = '/content/drive/MyDrive/GANFORMER_Duplex/' if duplex else '/content/drive/MyDrive/GANFORMER_Simplex/'\n",
        "else:\n",
        "    result_dir = '/content/drive/MyDrive/STYLEGAN2/'\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "train     = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "sched     = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "grid      = EasyDict(size='1080p', layout='random')                           # Options for setup_snapshot_image_grid().\n",
        "sc        = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "tf_config = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "\n",
        "if ganformer:\n",
        "  G = EasyDict(func_name='training.networks_GANFormer.G_GANformer', truncation_psi = 0.65, \n",
        "               architecture = 'resnet', latent_size = 32, \n",
        "               dlatent_size = 32, components_num = 16, \n",
        "               mapping_resnet = True, style = True, \n",
        "               fused_modconv = True, local_noise = True, \n",
        "               transformer = True, norm = 'layer', \n",
        "               integration = 'mul', kmeans = duplex, \n",
        "               kmeans_iters = 1, mapping_ltnt2ltnt = True, \n",
        "               use_pos = True, num_heads = 2, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               merge_layer = -1, start_res = 0, \n",
        "               end_res = base_2_log, img2img = 0, \n",
        "               style_mixing = 0.9, component_mixing = 0.0, \n",
        "               component_dropout = 0.0)       # Options for generator network.\n",
        "\n",
        "  if attention_discriminator:\n",
        "    func_name='training.networks_GANFormer.D_GANformer'\n",
        "  else:\n",
        "    func_name='training.networks_GANFormer.D_Stylegan'\n",
        "    \n",
        "  D = EasyDict(func_name=func_name, latent_size = 32,\n",
        "               components_num = 16, mbstd_group_size = 4, \n",
        "               use_pos = True, num_heads = 2, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               start_res = 0, end_res = base_2_log, img2img = 0)  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss.D_logistic_r1')              # Options for discriminator loss.\n",
        "  # G_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for generator optimizer.\n",
        "  # D_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for discriminator optimizer.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'GANFormer'\n",
        "else:\n",
        "  G = EasyDict(func_name='training.networks_stylegan2.G_main')       # Options for generator network.\n",
        "  D = EasyDict(func_name='training.networks_stylegan2.D_stylegan2')  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss_stylegan2.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss_stylegan2.D_logistic_r1')              # Options for discriminator loss.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'stylegan2'\n",
        "\n",
        "\n",
        "\n",
        "train.data_dir = data_dir\n",
        "train.total_kimg = total_kimg\n",
        "train.mirror_augment = mirror_augment\n",
        "train.image_snapshot_ticks = train.network_snapshot_ticks = 1\n",
        "sched.G_lrate_base = sched.D_lrate_base = 0.002\n",
        "sched.minibatch_size_base = 24\n",
        "sched.minibatch_gpu_base = 12\n",
        "D_loss.gamma = 10\n",
        "metrics = [metric_defaults[x] for x in metrics]\n",
        "metrics_10k = [metric_defaults[x] for x in metrics_10k]\n",
        "\n",
        "\n",
        "desc += '-' + dataset\n",
        "dataset_args = EasyDict(tfrecord_dir=dataset, resolution=img_resolution)\n",
        "\n",
        "assert num_gpus in [1, 2, 4, 8]\n",
        "sc.num_gpus = num_gpus\n",
        "desc += '-%dgpu' % num_gpus\n",
        "\n",
        "if gamma is not None:\n",
        "    D_loss.gamma = gamma\n",
        "\n",
        "sc.submit_target = dnnlib.SubmitTarget.LOCAL\n",
        "sc.local.do_not_copy_source_files = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "kwargs = EasyDict(train)\n",
        "kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "kwargs.update(dataset_args=dataset_args, sched_args=sched, grid_args=grid, metric_arg_list=metrics, metrics_10k_arg_list=metrics_10k, tf_config=tf_config,tick_size=tick_size, ganformer=ganformer,resume_pkl=None,resume_kimg =300)\n",
        "kwargs.submit_config = copy.deepcopy(sc)\n",
        "kwargs.submit_config.run_dir_root = result_dir\n",
        "kwargs.submit_config.run_desc = desc\n",
        "dnnlib.submit_run(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwzV3TjcM36K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dc427a-e278-4380-d00e-b3a1dac377ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: /content/drive/MyDrive/GANFORMER_Simplex/00000-GANFormer-custom-1gpu\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561301af0000 @  0x7efd6ad7b001 0x7efd678421af 0x7efd67898c23 0x7efd67899a87 0x7efd6793b823 0x5612fa45d11c 0x5612fa45cef0 0x5612fa4d164d 0x5612fa4cbcdd 0x5612fa45f13c 0x5612fa4a0239 0x5612fa49d184 0x5612fa45f341 0x5612fa4cdff1 0x5612fa4cba2e 0x5612fa39de2b 0x5612fa4cdff1 0x5612fa4cba2e 0x5612fa39de2b 0x5612fa4cdff1 0x5612fa45e7aa 0x5612fa4cc8f6 0x5612fa45e7aa 0x5612fa4ccb4f 0x5612fa4cba2e 0x5612fa39de2b 0x5612fa4cdff1 0x5612fa4cba2e 0x5612fa4cb723 0x5612fa595812 0x5612fa595b8d\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561401af0000 @  0x7efd6ad791e7 0x7efd678420ce 0x7efd67898cf5 0x7efd67898f4f 0x7efd6793b673 0x5612fa45d11c 0x5612fa45cef0 0x5612fa4d164d 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4cd719 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4cd719 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4cd719 0x5612fa45e7aa 0x5612fa4cc8f6 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4d0d30 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4cd719 0x5612fa4cbcdd 0x5612fa45f13c 0x5612fa4a0239 0x5612fa49d184 0x5612fa45f341 0x5612fa4cdff1\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5615036a2000 @  0x7efd6ad791e7 0x7efd678420ce 0x7efd67898cf5 0x7efd67898f4f 0x7efd1c330235 0x7efd1bcb3792 0x7efd1bcb3d42 0x7efd1bc6caee 0x5612fa45d0e7 0x5612fa45cef0 0x5612fa4d1123 0x5612fa45e7aa 0x5612fa4ccb4f 0x5612fa4cbcdd 0x5612fa39deb0 0x5612fa4cdff1 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4ccb4f 0x5612fa4cbcdd 0x5612fa45e88a 0x5612fa4ccb4f 0x5612fa45e7aa 0x5612fa4ccb4f 0x5612fa4cba2e 0x5612fa45ef21 0x5612fa45f341 0x5612fa4cdff1 0x5612fa4cba2e 0x5612fa45e88a 0x5612fa4cc8f6\n",
            "Dataset shape = [1, 32, 32]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... "
          ]
        }
      ],
      "source": [
        "!python3 run_training.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Reproducibility_model_trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}